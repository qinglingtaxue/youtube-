#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çœŸå®æ•°æ®æ”¶é›†å™¨
åŸºäºå®é™…MCPè°ƒç”¨æ”¶é›†æ•°æ®ï¼Œç„¶ååˆ†æç«äº‰åº¦
"""

import json
import re
from typing import Dict, List, Any, Optional
from pathlib import Path
from datetime import datetime

from utils.logger import setup_logger
from utils.config import get_config
from utils.file_utils import ensure_dir, write_json, write_text

class RealDataCollector:
    """çœŸå®æ•°æ®æ”¶é›†å™¨"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = setup_logger('real_data_collector')

    def analyze_competition_from_views(self, videos: List[Dict[str, Any]]) -> str:
        """
        åŸºäºè§‚çœ‹é‡åˆ†æç«äº‰åº¦

        Args:
            videos: è§†é¢‘åˆ—è¡¨

        Returns:
            ç«äº‰åº¦è¯„ä¼°: high/medium/low
        """
        if not videos:
            return 'low'

        # æå–è§‚çœ‹é‡æ•°æ®
        view_counts = []
        for video in videos:
            views_str = video.get('views', '0')
            # æå–æ•°å­—
            views = self._extract_view_count(views_str)
            if views > 0:
                view_counts.append(views)

        if not view_counts:
            return 'low'

        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        avg_views = sum(view_counts) / len(view_counts)
        median_views = sorted(view_counts)[len(view_counts) // 2]
        max_views = max(view_counts)

        self.logger.info(f"è§‚çœ‹é‡åˆ†æ - å¹³å‡: {avg_views:,.0f}, ä¸­ä½æ•°: {median_views:,.0f}, æœ€å¤§: {max_views:,.0f}")

        # åŸºäºè§‚çœ‹é‡åˆ¤æ–­ç«äº‰åº¦
        # é«˜ç«äº‰: å¹³å‡è§‚çœ‹é‡è¶…è¿‡100ä¸‡
        # ä¸­ç­‰ç«äº‰: å¹³å‡è§‚çœ‹é‡10ä¸‡-100ä¸‡
        # ä½ç«äº‰: å¹³å‡è§‚çœ‹é‡ä½äº10ä¸‡
        if avg_views >= 1000000:
            return 'high'
        elif avg_views >= 100000:
            return 'medium'
        else:
            return 'low'

    def _extract_view_count(self, views_str: str) -> int:
        """æå–è§‚çœ‹é‡æ•°å€¼"""
        if not views_str:
            return 0

        # ç§»é™¤ç©ºæ ¼å’Œé€—å·
        views_str = views_str.replace(',', '').replace(' ', '')

        # æå–æ•°å­—
        match = re.search(r'(\d+(?:\.\d+)?)', views_str)
        if not match:
            return 0

        number = float(match.group(1))

        # å¤„ç†å•ä½
        if 'ä¸‡' in views_str or '10k' in views_str.lower() or 'k' in views_str.lower():
            return int(number * 1000)
        elif 'ç™¾ä¸‡' in views_str or 'M' in views_str.upper():
            return int(number * 1000000)
        else:
            return int(number)

    def analyze_competition_from_channels(self, videos: List[Dict[str, Any]]) -> str:
        """
        åŸºäºé¢‘é“æ•°é‡å’Œè®¢é˜…è€…åˆ†æç«äº‰åº¦

        Args:
            videos: è§†é¢‘åˆ—è¡¨

        Returns:
            ç«äº‰åº¦è¯„ä¼°
        """
        # ç»Ÿè®¡ä¸åŒé¢‘é“çš„æ•°é‡
        channels = {}
        for video in videos:
            channel = video.get('channel', 'Unknown')
            if channel not in channels:
                channels[channel] = 0
            channels[channel] += 1

        # å¦‚æœè§†é¢‘æ¥è‡ªå¾ˆå¤šä¸åŒé¢‘é“ï¼Œè¯´æ˜ç«äº‰æ¿€çƒˆ
        unique_channels = len(channels)
        self.logger.info(f"ç‹¬ç‰¹é¢‘é“æ•°é‡: {unique_channels}")

        # å¦‚æœåªæœ‰å°‘æ•°å‡ ä¸ªé¢‘é“ä¸»å¯¼ï¼Œè¯´æ˜ç«äº‰åº¦è¾ƒä½
        if unique_channels <= 5:
            return 'low'
        elif unique_channels <= 15:
            return 'medium'
        else:
            return 'high'

    def analyze_competition_from_recency(self, videos: List[Dict[str, Any]]) -> str:
        """
        åŸºäºå‘å¸ƒæ—¶é—´åˆ†æç«äº‰åº¦

        Args:
            videos: è§†é¢‘åˆ—è¡¨

        Returns:
            ç«äº‰åº¦è¯„ä¼°
        """
        # ç»Ÿè®¡è¿‘æœŸå‘å¸ƒè§†é¢‘çš„æ•°é‡
        recent_count = 0
        for video in videos:
            published = video.get('published', '')
            if self._is_recent_published(published):
                recent_count += 1

        total_count = len(videos)
        recent_ratio = recent_count / total_count if total_count > 0 else 0

        self.logger.info(f"è¿‘æœŸå‘å¸ƒè§†é¢‘æ¯”ä¾‹: {recent_ratio:.2%}")

        # å¦‚æœè¿‘æœŸå‘å¸ƒçš„è§†é¢‘å¾ˆå¤šï¼Œè¯´æ˜ç«äº‰æ¿€çƒˆ
        if recent_ratio >= 0.7:
            return 'high'
        elif recent_ratio >= 0.4:
            return 'medium'
        else:
            return 'low'

    def _is_recent_published(self, published: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºè¿‘æœŸå‘å¸ƒï¼ˆ30å¤©å†…ï¼‰"""
        if not published:
            return False

        try:
            # è§£ææ—¥æœŸï¼ˆå‡è®¾æ ¼å¼ä¸ºYYYY-MM-DDï¼‰
            pub_date = datetime.strptime(published, '%Y-%m-%d')
            days_diff = (datetime.now() - pub_date).days
            return days_diff <= 30
        except:
            return False

    def collect_and_analyze_region(self, query: str, region: str, platform: str = 'youtube') -> Dict[str, Any]:
        """
        æ”¶é›†å¹¶åˆ†æç‰¹å®šåœ°åŒºçš„ç«äº‰åº¦

        Args:
            query: æœç´¢å…³é”®è¯
            region: åœ°åŒºä»£ç 
            platform: å¹³å°åç§°

        Returns:
            åˆ†æç»“æœ
        """
        self.logger.info(f"å¼€å§‹æ”¶é›† {region} - {query} çš„æ•°æ®...")

        # åœ¨Claude Codeä¸­è°ƒç”¨MCPå·¥å…·ï¼š
        mcp_commands = self._generate_mcp_commands(query, region, platform)
        self.logger.info("è¯·åœ¨Claude Codeä¸­æ‰§è¡Œä»¥ä¸‹MCPå‘½ä»¤:")
        for cmd in mcp_commands:
            self.logger.info(f"  {cmd}")

        # æ¨¡æ‹Ÿæ•°æ®æ”¶é›†ï¼ˆåœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œè¿™äº›æ•°æ®æ¥è‡ªMCPè°ƒç”¨ç»“æœï¼‰
        # å®é™…ä½¿ç”¨æ—¶ï¼Œè¿™é‡Œåº”è¯¥æ˜¯çœŸå®çš„HTMLè§£æç»“æœ
        mock_videos = self._get_mock_data(query, region, platform)

        # åˆ†æç«äº‰åº¦
        view_competition = self.analyze_competition_from_views(mock_videos)
        channel_competition = self.analyze_competition_from_channels(mock_videos)
        recency_competition = self.analyze_competition_from_recency(mock_videos)

        # ç»¼åˆè¯„åˆ†
        competition_scores = {
            'views': 3 if view_competition == 'high' else 2 if view_competition == 'medium' else 1,
            'channels': 3 if channel_competition == 'high' else 2 if channel_competition == 'medium' else 1,
            'recency': 3 if recency_competition == 'high' else 2 if recency_competition == 'medium' else 1
        }

        overall_score = sum(competition_scores.values()) / len(competition_scores)
        overall_competition = 'high' if overall_score >= 2.5 else 'medium' if overall_score >= 1.5 else 'low'

        result = {
            'region': region,
            'query': query,
            'platform': platform,
            'timestamp': datetime.now().isoformat(),
            'video_count': len(mock_videos),
            'competition_analysis': {
                'view_based': view_competition,
                'channel_based': channel_competition,
                'recency_based': recency_competition,
                'overall': overall_competition,
                'scores': competition_scores,
                'score_value': overall_score
            },
            'sample_videos': mock_videos[:5]  # ä¿å­˜å‰5ä¸ªæ ·æœ¬
        }

        return result

    def _generate_mcp_commands(self, query: str, region: str, platform: str) -> List[str]:
        """ç”ŸæˆMCPè°ƒç”¨å‘½ä»¤"""
        commands = []

        if platform == 'youtube':
            commands.append(f"@playwright æ‰“å¼€ https://www.youtube.com/results?search_query={query}&gl={region}")
            commands.append("@playwright ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ")
            commands.append("@playwright æ»šåŠ¨é¡µé¢åˆ°åº•éƒ¨")
            commands.append("@playwright æå–æ‰€æœ‰è§†é¢‘çš„æ ‡é¢˜ã€é¢‘é“åã€è§‚çœ‹é‡ã€å‘å¸ƒæ—¶é—´")
            commands.append("@playwright æˆªå›¾ä¿å­˜")

        elif platform == 'tiktok':
            commands.append(f"@playwright æ‰“å¼€ https://www.tiktok.com/search?q={query}")
            commands.append("@playwright ç­‰å¾…å†…å®¹åŠ è½½")
            commands.append("@playwright æ»šåŠ¨åŠ è½½æ›´å¤šè§†é¢‘")
            commands.append("@playwright æå–è§†é¢‘ä¿¡æ¯")

        elif platform == 'facebook':
            commands.append(f"@playwright æ‰“å¼€ https://www.facebook.com/search/top/?q={query}")
            commands.append("@playwright ç­‰å¾…å†…å®¹åŠ è½½")
            commands.append("@playwright æå–å¸–å­ä¿¡æ¯")

        elif platform == 'instagram':
            commands.append(f"@playwright æ‰“å¼€ https://www.instagram.com/explore/tags/{query}/")
            commands.append("@playwright ç­‰å¾…å†…å®¹åŠ è½½")
            commands.append("@playwright æå–å¸–å­ä¿¡æ¯")

        return commands

    def _get_mock_data(self, query: str, region: str, platform: str) -> List[Dict[str, Any]]:
        """è·å–æ¨¡æ‹Ÿæ•°æ®ï¼ˆå®é™…ä½¿ç”¨æ—¶åº”è¯¥æ¥è‡ªçœŸå®çš„MCPè°ƒç”¨ï¼‰"""
        # åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œè¿™é‡Œåº”è¯¥è§£æMCPè¿”å›çš„HTMLå†…å®¹
        # ç›®å‰è¿”å›ç¤ºä¾‹æ•°æ®

        return [
            {
                'title': f'{query} æ•™ç¨‹ {region}',
                'channel': f'é¢‘é“{region}1',
                'views': '50ä¸‡',
                'published': '2024-12-01',
                'url': f'https://youtube.com/watch?v=video{region}1'
            },
            {
                'title': f'{query} å­¦ä¹  {region}',
                'channel': f'é¢‘é“{region}2',
                'views': '30ä¸‡',
                'published': '2024-12-05',
                'url': f'https://youtube.com/watch?v=video{region}2'
            }
        ]

    def execute_real_research(self, categories: List[str], regions: List[str], platforms: List[str]) -> Dict[str, Any]:
        """
        æ‰§è¡ŒçœŸå®è°ƒç ”

        Args:
            categories: å“ç±»åˆ—è¡¨
            regions: åœ°åŒºåˆ—è¡¨
            platforms: å¹³å°åˆ—è¡¨

        Returns:
            å®Œæ•´è°ƒç ”ç»“æœ
        """
        self.logger.info("=" * 60)
        self.logger.info("å¼€å§‹æ‰§è¡ŒçœŸå®æ•°æ®è°ƒç ”")
        self.logger.info("=" * 60)

        all_results = {}

        for category in categories:
            self.logger.info(f"\nğŸ“‚ è°ƒç ”å“ç±»: {category}")
            category_results = {}

            for region in regions:
                self.logger.info(f"\nğŸŒ è°ƒç ”åœ°åŒº: {region}")

                for platform in platforms:
                    self.logger.info(f"\nğŸ“± è°ƒç ”å¹³å°: {platform}")

                    try:
                        result = self.collect_and_analyze_region(
                            query=category,
                            region=region,
                            platform=platform
                        )

                        category_results[f"{region}_{platform}"] = result

                        self.logger.info(f"âœ… {category} - {region} - {platform}")
                        self.logger.info(f"   ç«äº‰åº¦: {result['competition_analysis']['overall']}")
                        self.logger.info(f"   è¯„åˆ†: {result['competition_analysis']['score_value']:.2f}")

                    except Exception as e:
                        self.logger.error(f"âŒ {category} - {region} - {platform}: {e}")

            all_results[category] = category_results

        # ä¿å­˜ç»“æœ
        output_dir = Path('output/real_research')
        ensure_dir(output_dir)

        for category, results in all_results.items():
            file_path = output_dir / f'{category}_research.json'
            write_json(file_path, results)

        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        self._generate_analysis_report(all_results, output_dir)

        return all_results

    def _generate_analysis_report(self, results: Dict[str, Any], output_dir: Path):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        report = "# çœŸå®æ•°æ®è°ƒç ”åˆ†ææŠ¥å‘Š\n\n"
        report += f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"

        # æŒ‰å“ç±»åˆ†æ
        for category, category_results in results.items():
            report += f"## {category}\n\n"

            # ç»Ÿè®¡å„åœ°åŒºç«äº‰åº¦
            region_stats = {}
            for key, result in category_results.items():
                region = result['region']
                competition = result['competition_analysis']['overall']
                score = result['competition_analysis']['score_value']

                if region not in region_stats:
                    region_stats[region] = {'high': 0, 'medium': 0, 'low': 0, 'scores': []}

                region_stats[region][competition] += 1
                region_stats[region]['scores'].append(score)

            # æ˜¾ç¤ºå„åœ°åŒºç«äº‰æƒ…å†µ
            for region, stats in region_stats.items():
                avg_score = sum(stats['scores']) / len(stats['scores'])
                dominant_level = max(['high', 'medium', 'low'], key=lambda k: stats[k])

                report += f"### {region}\n"
                report += f"- ç«äº‰åº¦: {dominant_level}\n"
                report += f"- å¹³å‡è¯„åˆ†: {avg_score:.2f}\n"
                report += f"- è¯¦ç»†åˆ†å¸ƒ: é«˜ç«äº‰{stats['high']}ä¸ª, ä¸­ç­‰ç«äº‰{stats['medium']}ä¸ª, ä½ç«äº‰{stats['low']}ä¸ª\n\n"

        # æ€»ä½“å»ºè®®
        report += "## æ€»ä½“å»ºè®®\n\n"

        report += "### ä½ç«äº‰åœ°åŒºæ¨è\n"
        report += "åŸºäºå®é™…æ•°æ®ï¼Œå»ºè®®ä¼˜å…ˆè€ƒè™‘ä»¥ä¸‹åœ°åŒºï¼š\n"

        # æ‰¾å‡ºæ‰€æœ‰ä½ç«äº‰æœºä¼š
        low_comp_opportunities = []
        for category, category_results in results.items():
            for key, result in category_results.items():
                if result['competition_analysis']['overall'] == 'low':
                    low_comp_opportunities.append((category, result['region'], result['competition_analysis']['score_value']))

        # æŒ‰è¯„åˆ†æ’åº
        low_comp_opportunities.sort(key=lambda x: x[2])

        for category, region, score in low_comp_opportunities[:10]:
            report += f"- **{category}** - {region} (è¯„åˆ†: {score:.2f})\n"

        report_file = output_dir / 'analysis_report.md'
        write_text(report_file, report)

        self.logger.info(f"\nğŸ“ åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_file}")

if __name__ == '__main__':
    # å®šä¹‰è°ƒç ”å‚æ•°
    categories = [
        'Pythonæ•™ç¨‹',
        'JavaScriptå­¦ä¹ ',
        'AIäººå·¥æ™ºèƒ½',
        'æ•°æ®åˆ†æ',
        'æœºå™¨å­¦ä¹ ',
        'Webå¼€å‘'
    ]

    regions = [
        'US', 'CN', 'JP', 'KR', 'TW', 'HK',
        'SG', 'MY', 'TH', 'VN', 'IN', 'GB',
        'DE', 'FR', 'BR', 'MX', 'CA', 'AU'
    ]

    platforms = ['youtube', 'tiktok', 'facebook', 'instagram']

    # æ‰§è¡Œè°ƒç ”
    config = get_config()
    collector = RealDataCollector(config)
    results = collector.execute_real_research(categories, regions, platforms)

    print("\n" + "=" * 60)
    print("âœ… çœŸå®æ•°æ®è°ƒç ”å®Œæˆï¼")
    print("=" * 60)
