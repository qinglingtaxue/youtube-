#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºMCP Fetchçš„æ•°æ®æ”¶é›†å™¨
ä½¿ç”¨mcp-server-fetchè¿›è¡ŒçœŸå®çš„ç½‘é¡µæµè§ˆå’Œæ•°æ®æ”¶é›†
æ›¿ä»£YouTube APIæ–¹æ¡ˆ
"""

import sys
import json
import re
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime
from urllib.parse import urljoin, urlparse

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from utils.logger import setup_logger
from utils.config import get_config
from utils.file_utils import ensure_dir, write_json
from utils.validators import validate_string, sanitize_filename

logger = setup_logger('mcp_data_collector')

class MCPDataCollector:
    """åŸºäºMCP Fetchçš„æ•°æ®æ”¶é›†å™¨"""

    def __init__(self, config):
        """
        åˆå§‹åŒ–MCPæ•°æ®æ”¶é›†å™¨

        Args:
            config: é…ç½®å¯¹è±¡
        """
        self.config = config
        self.cache_dir = Path('cache/mcp_data')
        ensure_dir(self.cache_dir)
        logger.info("MCPæ•°æ®æ”¶é›†å™¨åˆå§‹åŒ–å®Œæˆ")

    def search_youtube_videos(self, query: str, max_results: int = 50) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨MCP Fetchæœç´¢YouTubeè§†é¢‘

        Args:
            query: æœç´¢å…³é”®è¯
            max_results: æœ€å¤§ç»“æœæ•°

        Returns:
            è§†é¢‘æ•°æ®åˆ—è¡¨
        """
        logger.info(f"ä½¿ç”¨MCP Fetchæœç´¢YouTubeè§†é¢‘: {query}")

        # æ„å»ºYouTubeæœç´¢URL
        search_url = f"https://www.youtube.com/results?search_query={query}&sp=CAI%253D"

        try:
            # ä½¿ç”¨MCP Fetchè·å–æœç´¢ç»“æœé¡µé¢
            html_content = self._fetch_with_mcp(search_url)

            # è§£æHTMLæå–è§†é¢‘ä¿¡æ¯
            videos = self._parse_youtube_search_results(html_content, query)

            # é™åˆ¶ç»“æœæ•°é‡
            videos = videos[:max_results]

            logger.info(f"æˆåŠŸè·å– {len(videos)} ä¸ªè§†é¢‘")

            # ä¿å­˜åŸå§‹æ•°æ®
            cache_file = self.cache_dir / f"search_{sanitize_filename(query)}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            write_json(cache_file, {
                'query': query,
                'timestamp': datetime.now().isoformat(),
                'videos': videos
            })

            return videos

        except Exception as e:
            logger.error(f"æœç´¢YouTubeè§†é¢‘å¤±è´¥: {e}")
            raise

    def get_video_details(self, video_url: str) -> Dict[str, Any]:
        """
        ä½¿ç”¨MCP Fetchè·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯

        Args:
            video_url: è§†é¢‘URL

        Returns:
            è§†é¢‘è¯¦ç»†ä¿¡æ¯
        """
        logger.debug(f"è·å–è§†é¢‘è¯¦æƒ…: {video_url}")

        try:
            # ä½¿ç”¨MCP Fetchè·å–è§†é¢‘é¡µé¢
            html_content = self._fetch_with_mcp(video_url)

            # è§£æè§†é¢‘ä¿¡æ¯
            video_info = self._parse_video_details(html_content, video_url)

            # ä¿å­˜è§†é¢‘è¯¦æƒ…
            cache_file = self.cache_dir / f"video_{video_info['id']}.json"
            write_json(cache_file, video_info)

            return video_info

        except Exception as e:
            logger.error(f"è·å–è§†é¢‘è¯¦æƒ…å¤±è´¥ {video_url}: {e}")
            raise

    def get_trending_videos(self, category: str = "", max_results: int = 50) -> List[Dict[str, Any]]:
        """
        è·å–çƒ­é—¨è§†é¢‘

        Args:
            category: è§†é¢‘åˆ†ç±»
            max_results: æœ€å¤§ç»“æœæ•°

        Returns:
            çƒ­é—¨è§†é¢‘åˆ—è¡¨
        """
        logger.info(f"è·å–çƒ­é—¨è§†é¢‘: {category or 'å…¨éƒ¨'}")

        try:
            # æ„å»ºçƒ­é—¨è§†é¢‘URL
            if category:
                trending_url = f"https://www.youtube.com/feed/trending"
            else:
                trending_url = "https://www.youtube.com/feed/trending"

            # ä½¿ç”¨MCP Fetchè·å–çƒ­é—¨é¡µé¢
            html_content = self._fetch_with_mcp(trending_url)

            # è§£æçƒ­é—¨è§†é¢‘
            videos = self._parse_trending_videos(html_content)

            # é™åˆ¶ç»“æœæ•°é‡
            videos = videos[:max_results]

            logger.info(f"æˆåŠŸè·å– {len(videos)} ä¸ªçƒ­é—¨è§†é¢‘")

            return videos

        except Exception as e:
            logger.error(f"è·å–çƒ­é—¨è§†é¢‘å¤±è´¥: {e}")
            raise

    def get_channel_videos(self, channel_url: str, max_results: int = 50) -> List[Dict[str, Any]]:
        """
        è·å–é¢‘é“è§†é¢‘

        Args:
            channel_url: é¢‘é“URL
            max_results: æœ€å¤§ç»“æœæ•°

        Returns:
            é¢‘é“è§†é¢‘åˆ—è¡¨
        """
        logger.info(f"è·å–é¢‘é“è§†é¢‘: {channel_url}")

        try:
            # ä½¿ç”¨MCP Fetchè·å–é¢‘é“é¡µé¢
            html_content = self._fetch_with_mcp(channel_url)

            # è§£æé¢‘é“è§†é¢‘
            videos = self._parse_channel_videos(html_content, channel_url)

            # é™åˆ¶ç»“æœæ•°é‡
            videos = videos[:max_results]

            logger.info(f"æˆåŠŸè·å– {len(videos)} ä¸ªé¢‘é“è§†é¢‘")

            return videos

        except Exception as e:
            logger.error(f"è·å–é¢‘é“è§†é¢‘å¤±è´¥ {channel_url}: {e}")
            raise

    def batch_collect_videos(self, urls: List[str], max_workers: int = 3) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡æ”¶é›†è§†é¢‘è¯¦æƒ…

        Args:
            urls: è§†é¢‘URLåˆ—è¡¨
            max_workers: å¹¶å‘æ•°

        Returns:
            è§†é¢‘è¯¦æƒ…åˆ—è¡¨
        """
        logger.info(f"æ‰¹é‡æ”¶é›† {len(urls)} ä¸ªè§†é¢‘è¯¦æƒ…")

        from concurrent.futures import ThreadPoolExecutor, as_completed

        videos = []
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_url = {
                executor.submit(self.get_video_details, url): url
                for url in urls
            }

            for future in as_completed(future_to_url):
                url = future_to_url[future]
                try:
                    video_info = future.result()
                    videos.append(video_info)
                    logger.debug(f"å·²æ”¶é›†: {video_info.get('title', url)}")
                except Exception as e:
                    logger.error(f"æ”¶é›†è§†é¢‘å¤±è´¥ {url}: {e}")

        logger.info(f"æ‰¹é‡æ”¶é›†å®Œæˆï¼ŒæˆåŠŸ {len(videos)}/{len(urls)} ä¸ª")
        return videos

    def _fetch_with_mcp(self, url: str) -> str:
        """
        ä½¿ç”¨MCP Fetchè·å–ç½‘é¡µå†…å®¹

        Args:
            url: ç›®æ ‡URL

        Returns:
            HTMLå†…å®¹
        """
        logger.debug(f"MCP Fetchè·å–: {url}")

        # æ³¨æ„ï¼šå®é™…ä½¿ç”¨ä¸­éœ€è¦é€šè¿‡Claude Codeè°ƒç”¨MCP fetch
        # è¿™é‡Œè¿”å›æ¨¡æ‹Ÿæ•°æ®ç”¨äºæ¼”ç¤º
        # å®é™…å®ç°ä¸­åº”è¯¥æ˜¯ï¼š
        # @fetch è·å– {url}

        # æ¨¡æ‹Ÿè¿”å›çš„HTMLå†…å®¹
        # å®é™…é¡¹ç›®ä¸­åº”è¯¥åœ¨Claude Codeä¸­è°ƒç”¨MCPå·¥å…·
        mock_html = f"""
        <!DOCTYPE html>
        <html>
        <head><title>Mock YouTube Page</title></head>
        <body>
            <script>
                // æ¨¡æ‹ŸYouTubeæ•°æ®ç»“æ„
                var ytInitialData = {{
                    "contents": {{
                        "twoColumnSearchResultsRenderer": {{
                            "primaryContents": {{
                                "sectionListRenderer": {{
                                    "contents": [
                                        {{
                                            "searchResultRenderer": {{
                                                "contents": [
                                                    {{
                                                        "videoRenderer": {{
                                                            "videoId": "mock123",
                                                            "title": {{"runs": [{{"text": "Mock Video for {url}"}}]}},
                                                            "viewCountText": {{"simpleText": "1,000,000æ¬¡è§‚çœ‹"}},
                                                            "lengthText": {{"simpleText": "10:30"}},
                                                            "ownerText": {{"runs": [{{"text": "Mock Channel"}}]}}
                                                        }}
                                                    }}
                                                ]
                                            }}
                                        }}
                                    ]
                                }}
                            }}
                        }}
                    }}
                }};
            </script>
        </body>
        </html>
        """

        logger.warning("å½“å‰ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼Œå®é™…ä½¿ç”¨éœ€è¦é€šè¿‡Claude Codeè°ƒç”¨MCP fetch")
        return mock_html

    def _parse_youtube_search_results(self, html_content: str, query: str) -> List[Dict[str, Any]]:
        """
        è§£æYouTubeæœç´¢ç»“æœ

        Args:
            html_content: HTMLå†…å®¹
            query: æœç´¢å…³é”®è¯

        Returns:
            è§†é¢‘åˆ—è¡¨
        """
        videos = []

        # å®é™…å®ç°ä¸­éœ€è¦è§£æHTMLæå–è§†é¢‘ä¿¡æ¯
        # è¿™é‡Œæä¾›è§£æé€»è¾‘ç¤ºä¾‹

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–è§†é¢‘ä¿¡æ¯ï¼ˆå®é™…ä¸­åº”ä½¿ç”¨æ›´å¼ºå¤§çš„HTMLè§£æå™¨ï¼‰
        video_patterns = re.findall(
            r'"videoRenderer":\s*{"videoId":\s*"([^"]+)"[^}]*"title":\s*{"runs":\s*\[{"text":\s*"([^"]+)"}]',
            html_content
        )

        for video_id, title in video_patterns:
            video_info = {
                'id': video_id,
                'title': title,
                'url': f"https://www.youtube.com/watch?v={video_id}",
                'search_query': query,
                'collected_at': datetime.now().isoformat()
            }
            videos.append(video_info)

        return videos

    def _parse_video_details(self, html_content: str, video_url: str) -> Dict[str, Any]:
        """
        è§£æè§†é¢‘è¯¦æƒ…é¡µé¢

        Args:
            html_content: HTMLå†…å®¹
            video_url: è§†é¢‘URL

        Returns:
            è§†é¢‘è¯¦ç»†ä¿¡æ¯
        """
        # æå–è§†é¢‘ID
        video_id_match = re.search(r'v=([^&]+)', video_url)
        video_id = video_id_match.group(1) if video_id_match else 'unknown'

        # å®é™…å®ç°ä¸­éœ€è¦è§£æHTMLæå–è¯¦ç»†ä¿¡æ¯
        video_info = {
            'id': video_id,
            'url': video_url,
            'title': 'è§£æçš„æ ‡é¢˜',
            'description': 'è§£æçš„æè¿°',
            'view_count': 0,
            'like_count': 0,
            'duration': 0,
            'published_at': datetime.now().isoformat(),
            'channel': 'è§£æçš„é¢‘é“',
            'tags': [],
            'collected_at': datetime.now().isoformat()
        }

        return video_info

    def _parse_trending_videos(self, html_content: str) -> List[Dict[str, Any]]:
        """
        è§£æçƒ­é—¨è§†é¢‘

        Args:
            html_content: HTMLå†…å®¹

        Returns:
            çƒ­é—¨è§†é¢‘åˆ—è¡¨
        """
        # ç±»ä¼¼æœç´¢ç»“æœè§£æï¼Œä½†ä¸“é—¨å¤„ç†çƒ­é—¨è§†é¢‘
        return []

    def _parse_channel_videos(self, html_content: str, channel_url: str) -> List[Dict[str, Any]]:
        """
        è§£æé¢‘é“è§†é¢‘

        Args:
            html_content: HTMLå†…å®¹
            channel_url: é¢‘é“URL

        Returns:
            é¢‘é“è§†é¢‘åˆ—è¡¨
        """
        # è§£æé¢‘é“é¡µé¢çš„è§†é¢‘åˆ—è¡¨
        return []

    def save_collected_data(self, videos: List[Dict[str, Any]], filename: str):
        """
        ä¿å­˜æ”¶é›†çš„æ•°æ®

        Args:
            videos: è§†é¢‘æ•°æ®åˆ—è¡¨
            filename: æ–‡ä»¶å
        """
        output_file = self.cache_dir / f"{sanitize_filename(filename)}.json"

        data = {
            'collection_info': {
                'timestamp': datetime.now().isoformat(),
                'video_count': len(videos),
                'source': 'mcp_fetch'
            },
            'videos': videos
        }

        write_json(output_file, data)
        logger.info(f"æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºMCPæ•°æ®æ”¶é›†å™¨ä½¿ç”¨"""
    config = get_config()
    collector = MCPDataCollector(config)

    print("\n" + "=" * 60)
    print("MCPæ•°æ®æ”¶é›†å™¨ - æ¼”ç¤ºæ¨¡å¼")
    print("=" * 60)
    print("\næ³¨æ„: å½“å‰è¿è¡Œåœ¨æ¼”ç¤ºæ¨¡å¼ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
    print("å®é™…ä½¿ç”¨éœ€è¦åœ¨Claude Codeä¸­è°ƒç”¨MCP fetchå·¥å…·\n")

    try:
        # æ¼”ç¤ºæœç´¢
        print("ğŸ” æ¼”ç¤º: æœç´¢YouTubeè§†é¢‘")
        videos = collector.search_youtube_videos("Pythonæ•™ç¨‹", max_results=5)
        print(f"è·å–åˆ° {len(videos)} ä¸ªè§†é¢‘")

        # æ¼”ç¤ºè·å–è§†é¢‘è¯¦æƒ…
        if videos:
            print("\nğŸ“¹ æ¼”ç¤º: è·å–è§†é¢‘è¯¦æƒ…")
            first_video = videos[0]
            details = collector.get_video_details(first_video['url'])
            print(f"è§†é¢‘æ ‡é¢˜: {details['title']}")

        print("\nâœ… æ¼”ç¤ºå®Œæˆ")
        print("\nğŸ’¡ æç¤º: å®é™…ä½¿ç”¨éœ€è¦åœ¨Claude Codeä¸­æ‰§è¡Œ:")
        print("  @fetch è·å– https://www.youtube.com/results?search_query=Pythonæ•™ç¨‹")

    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
