#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŠ¨æ€è¿½è¸ªæ¨¡å—
å®æ—¶ç›‘æ§YouTubeå¹³å°çš„æœ€æ–°åŠ¨æ€å’Œçƒ­ç‚¹è¶‹åŠ¿
ä¸é•¿æœŸæ¨¡å¼åˆ†æç»“åˆä½¿ç”¨
"""

import sys
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from utils.logger import setup_logger
from utils.config import get_config
from utils.file_utils import ensure_dir, write_json
from utils.validators import validate_string

logger = setup_logger('dynamic_tracker')

class DynamicTracker:
    """åŠ¨æ€è¿½è¸ªå™¨ - ç›‘æ§å®æ—¶è¶‹åŠ¿å’Œçƒ­ç‚¹"""

    def __init__(self, config):
        """
        åˆå§‹åŒ–åŠ¨æ€è¿½è¸ªå™¨

        Args:
            config: é…ç½®å¯¹è±¡
        """
        self.config = config
        self.trending_cache = {}
        self.hot_topics = []
        self.recent_videos = []

    def track_daily_trends(self, keywords: List[str]) -> Dict[str, Any]:
        """
        è¿½è¸ªæ¯æ—¥è¶‹åŠ¿

        Args:
            keywords: ç›‘æ§å…³é”®è¯åˆ—è¡¨

        Returns:
            è¶‹åŠ¿æ•°æ®
        """
        logger.info(f"å¼€å§‹è¿½è¸ª {len(keywords)} ä¸ªå…³é”®è¯çš„æ¯æ—¥è¶‹åŠ¿")

        trends = {
            'timestamp': datetime.now().isoformat(),
            'keywords': keywords,
            'daily_stats': {},
            'emerging_topics': [],
            'declining_topics': [],
            'viral_videos': []
        }

        for keyword in keywords:
            logger.debug(f"åˆ†æå…³é”®è¯: {keyword}")

            # è·å–è¿‡å»24å°æ—¶çš„æ•°æ®
            recent_data = self._get_recent_videos(keyword, hours=24)

            # åˆ†æè¶‹åŠ¿
            trend_analysis = self._analyze_daily_trend(keyword, recent_data)
            trends['daily_stats'][keyword] = trend_analysis

            # è¯†åˆ«æ–°å…´è¯é¢˜
            if trend_analysis.get('growth_rate', 0) > 2.0:  # å¢é•¿ç‡è¶…è¿‡200%
                trends['emerging_topics'].append({
                    'keyword': keyword,
                    'growth_rate': trend_analysis['growth_rate'],
                    'reason': trend_analysis.get('reason', 'N/A')
                })

            # è¯†åˆ«è¡°é€€è¯é¢˜
            if trend_analysis.get('growth_rate', 0) < 0.5:  # å¢é•¿ç‡ä½äº50%
                trends['declining_topics'].append({
                    'keyword': keyword,
                    'growth_rate': trend_analysis['growth_rate']
                })

            # è¯†åˆ«ç—…æ¯’è§†é¢‘
            viral = self._identify_viral_videos(recent_data)
            if viral:
                trends['viral_videos'].extend(viral)

        # æ’åºç—…æ¯’è§†é¢‘
        trends['viral_videos'].sort(key=lambda x: x.get('velocity', 0), reverse=True)
        trends['viral_videos'] = trends['viral_videos'][:10]  # åªä¿ç•™å‰10ä¸ª

        return trends

    def monitor_competitor_activity(self, channels: List[str]) -> Dict[str, Any]:
        """
        ç›‘æ§ç«å“é¢‘é“æ´»åŠ¨

        Args:
            channels: ç«å“é¢‘é“åˆ—è¡¨

        Returns:
            ç«å“æ´»åŠ¨æ•°æ®
        """
        logger.info(f"ç›‘æ§ {len(channels)} ä¸ªç«å“é¢‘é“çš„æ´»åŠ¨")

        activity = {
            'timestamp': datetime.now().isoformat(),
            'channels': channels,
            'channel_activity': {},
            'content_patterns': {},
            'posting_schedule': {},
            'performance_comparison': {}
        }

        for channel in channels:
            try:
                # è·å–é¢‘é“æœ€æ–°è§†é¢‘
                recent_videos = self._get_channel_videos(channel, days=7)

                # åˆ†æå‘å¸ƒæ¨¡å¼
                schedule = self._analyze_posting_schedule(recent_videos)
                activity['posting_schedule'][channel] = schedule

                # åˆ†æå†…å®¹æ¨¡å¼
                patterns = self._analyze_channel_patterns(recent_videos)
                activity['content_patterns'][channel] = patterns

                # æ€§èƒ½å¯¹æ¯”
                performance = self._compare_performance(recent_videos)
                activity['performance_comparison'][channel] = performance

                activity['channel_activity'][channel] = {
                    'video_count': len(recent_videos),
                    'avg_views': sum(v.get('view_count', 0) for v in recent_videos) / len(recent_videos) if recent_videos else 0,
                    'total_engagement': sum(v.get('view_count', 0) + v.get('like_count', 0) for v in recent_videos),
                    'latest_video': recent_videos[0] if recent_videos else None
                }

            except Exception as e:
                logger.error(f"ç›‘æ§é¢‘é“ {channel} æ—¶å‡ºé”™: {e}")
                activity['channel_activity'][channel] = {'error': str(e)}

        return activity

    def track_platform_changes(self) -> Dict[str, Any]:
        """
        è¿½è¸ªå¹³å°å˜åŒ–

        Returns:
            å¹³å°å˜åŒ–æ•°æ®
        """
        logger.info("è¿½è¸ªYouTubeå¹³å°å˜åŒ–")

        # æ³¨æ„ï¼šå®é™…å®ç°ä¸­éœ€è¦è°ƒç”¨YouTube APIæˆ–ç¬¬ä¸‰æ–¹æœåŠ¡
        # è¿™é‡Œæä¾›ç¤ºä¾‹æ¡†æ¶

        platform_data = {
            'timestamp': datetime.now().isoformat(),
            'algorithm_updates': [],
            'policy_changes': [],
            'new_features': [],
            'recommendation_patterns': {}
        }

        # ç¤ºä¾‹ï¼šæ£€æµ‹ç®—æ³•æ›´æ–°
        algorithm_signals = self._detect_algorithm_changes()
        if algorithm_signals:
            platform_data['algorithm_updates'] = algorithm_signals

        # ç¤ºä¾‹ï¼šæ£€æµ‹æ”¿ç­–å˜åŒ–
        policy_signals = self._detect_policy_changes()
        if policy_signals:
            platform_data['policy_changes'] = policy_signals

        return platform_data

    def generate_daily_digest(self) -> str:
        """
        ç”Ÿæˆæ¯æ—¥åŠ¨æ€æ‘˜è¦

        Returns:
            æ ¼å¼åŒ–çš„æ‘˜è¦æŠ¥å‘Š
        """
        logger.info("ç”Ÿæˆæ¯æ—¥åŠ¨æ€æ‘˜è¦")

        # è·å–ä»Šæ—¥æ•°æ®
        trends = self.track_daily_trends(self.config.get('monitoring.keywords', []))
        competitors = self.monitor_competitor_activity(self.config.get('monitoring.competitors', []))
        platform = self.track_platform_changes()

        # ç”Ÿæˆæ‘˜è¦
        digest_lines = [
            "# YouTubeæ¯æ—¥åŠ¨æ€æ‘˜è¦",
            "",
            f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "## ğŸ”¥ ä»Šæ—¥çƒ­ç‚¹",
            ""
        ]

        # çƒ­ç‚¹è¯é¢˜
        if trends['emerging_topics']:
            digest_lines.append("### æ–°å…´è¯é¢˜")
            for topic in trends['emerging_topics']:
                digest_lines.append(f"- **{topic['keyword']}**: å¢é•¿ç‡ {topic['growth_rate']:.1%}")
            digest_lines.append("")

        # ç—…æ¯’è§†é¢‘
        if trends['viral_videos']:
            digest_lines.append("### ç—…æ¯’è§†é¢‘")
            for video in trends['viral_videos'][:5]:
                digest_lines.append(f"- [{video['title'][:50]}...]({video['url']})")
                digest_lines.append(f"  å¢é•¿é€Ÿç‡: {video.get('velocity', 0):.1f}x")
            digest_lines.append("")

        # ç«å“åŠ¨æ€
        if competitors['channel_activity']:
            digest_lines.append("## ğŸ“Š ç«å“åŠ¨æ€")
            for channel, activity in list(competitors['channel_activity'].items())[:5]:
                if 'error' not in activity:
                    digest_lines.append(f"### {channel}")
                    digest_lines.append(f"- ä»Šæ—¥å‘å¸ƒ: {activity.get('video_count', 0)} ä¸ªè§†é¢‘")
                    digest_lines.append(f"- å¹³å‡è§‚çœ‹: {activity.get('avg_views', 0):,.0f}")
                    if activity.get('latest_video'):
                        digest_lines.append(f"- æœ€æ–°: {activity['latest_video']['title'][:30]}...")
                    digest_lines.append("")

        # å¹³å°å˜åŒ–
        if platform['algorithm_updates'] or platform['policy_changes']:
            digest_lines.append("## âš¡ å¹³å°å˜åŒ–")
            for update in platform['algorithm_updates']:
                digest_lines.append(f"- **ç®—æ³•æ›´æ–°**: {update}")
            for change in platform['policy_changes']:
                digest_lines.append(f"- **æ”¿ç­–å˜åŒ–**: {change}")
            digest_lines.append("")

        # è¡ŒåŠ¨å»ºè®®
        digest_lines.extend([
            "## ğŸ’¡ è¡ŒåŠ¨å»ºè®®",
            "",
            "1. **å…³æ³¨æ–°å…´è¯é¢˜**: å¿«é€Ÿè·Ÿè¿›å¢é•¿ç‡è¶…è¿‡200%çš„è¯é¢˜",
            "2. **å­¦ä¹ ç—…æ¯’å†…å®¹**: åˆ†æé«˜å¢é•¿è§†é¢‘çš„å…±åŒç‰¹å¾",
            "3. **ç«å“ç­–ç•¥è°ƒæ•´**: æ ¹æ®ç«å“è¡¨ç°è°ƒæ•´è‡ªå·±çš„å†…å®¹ç­–ç•¥",
            "4. **å¹³å°è§„åˆ™é€‚åº”**: åŠæ—¶é€‚åº”ç®—æ³•å’Œæ”¿ç­–å˜åŒ–",
            ""
        ])

        return '\n'.join(digest_lines)

    def _get_recent_videos(self, keyword: str, hours: int = 24) -> List[Dict[str, Any]]:
        """è·å–æœ€è¿‘è§†é¢‘ï¼ˆç¤ºä¾‹å®ç°ï¼‰"""
        # å®é™…å®ç°ä¸­è°ƒç”¨YouTube API
        # è¿™é‡Œè¿”å›ç¤ºä¾‹æ•°æ®
        return []

    def _analyze_daily_trend(self, keyword: str, videos: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†ææ¯æ—¥è¶‹åŠ¿"""
        if not videos:
            return {'growth_rate': 0, 'reason': 'æ— æ•°æ®'}

        # è®¡ç®—å¢é•¿ç‡ï¼ˆç¤ºä¾‹é€»è¾‘ï¼‰
        recent_views = sum(v.get('view_count', 0) for v in videos)
        baseline = recent_views * 0.3  # å‡è®¾åŸºå‡†æ˜¯æœ€è¿‘çš„30%
        growth_rate = recent_views / baseline if baseline > 0 else 0

        return {
            'growth_rate': growth_rate,
            'reason': self._identify_trend_reason(videos),
            'total_views': recent_views,
            'video_count': len(videos),
            'avg_velocity': recent_views / len(videos) if videos else 0
        }

    def _identify_viral_videos(self, videos: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """è¯†åˆ«ç—…æ¯’è§†é¢‘"""
        viral = []
        for video in videos:
            velocity = video.get('view_count', 0) / max(video.get('hours_since_publish', 24), 1)
            if velocity > 1000:  # æ¯å°æ—¶è¶…è¿‡1000è§‚çœ‹
                viral.append({
                    'title': video.get('title', ''),
                    'url': video.get('url', ''),
                    'velocity': velocity,
                    'channel': video.get('channel', ''),
                    'reason': 'é«˜å¢é•¿é€Ÿç‡'
                })
        return viral

    def _get_channel_videos(self, channel: str, days: int = 7) -> List[Dict[str, Any]]:
        """è·å–é¢‘é“è§†é¢‘ï¼ˆç¤ºä¾‹å®ç°ï¼‰"""
        # å®é™…å®ç°ä¸­è°ƒç”¨YouTube API
        return []

    def _analyze_posting_schedule(self, videos: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æå‘å¸ƒæ—¶é—´æ¨¡å¼"""
        if not videos:
            return {}

        # åˆ†æå‘å¸ƒæ—¶é—´åˆ†å¸ƒ
        time_distribution = {}
        for video in videos:
            publish_time = video.get('published_at', '')
            if publish_time:
                hour = datetime.fromisoformat(publish_time).hour
                time_distribution[hour] = time_distribution.get(hour, 0) + 1

        # æ‰¾å‡ºæœ€ä½³å‘å¸ƒæ—¶é—´
        best_hours = sorted(time_distribution.items(), key=lambda x: x[1], reverse=True)[:3]

        return {
            'time_distribution': time_distribution,
            'best_hours': [h[0] for h in best_hours],
            'posting_frequency': len(videos) / 7  # æ¯å‘¨å‘å¸ƒæ•°
        }

    def _analyze_channel_patterns(self, videos: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æé¢‘é“å†…å®¹æ¨¡å¼"""
        if not videos:
            return {}

        # åˆ†ææ ‡é¢˜æ¨¡å¼
        titles = [v.get('title', '') for v in videos]
        common_words = self._extract_common_words(titles)

        # åˆ†ææ ‡ç­¾æ¨¡å¼
        all_tags = []
        for video in videos:
            all_tags.extend(video.get('tags', []))
        tag_frequency = self._count_frequency(all_tags)

        return {
            'title_patterns': common_words,
            'top_tags': tag_frequency[:10],
            'avg_video_length': sum(v.get('duration', 0) for v in videos) / len(videos),
            'content_themes': list(common_words.keys())[:5]
        }

    def _compare_performance(self, videos: List[Dict[str, Any]]) -> Dict[str, Any]:
        """å¯¹æ¯”æ€§èƒ½è¡¨ç°"""
        if not videos:
            return {}

        views = [v.get('view_count', 0) for v in videos]
        engagement = [v.get('like_count', 0) + v.get('comment_count', 0) for v in videos]

        return {
            'avg_views': sum(views) / len(views),
            'avg_engagement': sum(engagement) / len(engagement),
            'engagement_rate': sum(engagement) / sum(views) if sum(views) > 0 else 0,
            'top_performing': max(videos, key=lambda x: x.get('view_count', 0))
        }

    def _detect_algorithm_changes(self) -> List[str]:
        """æ£€æµ‹ç®—æ³•å˜åŒ–ï¼ˆç¤ºä¾‹å®ç°ï¼‰"""
        # å®é™…å®ç°ä¸­éœ€è¦åˆ†ææ¨èæ¨¡å¼çš„å˜åŒ–
        # è¿™é‡Œè¿”å›ç¤ºä¾‹æ•°æ®
        return []

    def _detect_policy_changes(self) -> List[str]:
        """æ£€æµ‹æ”¿ç­–å˜åŒ–ï¼ˆç¤ºä¾‹å®ç°ï¼‰"""
        # å®é™…å®ç°ä¸­éœ€è¦ç›‘æ§YouTubeå®˜æ–¹æ”¿ç­–æ›´æ–°
        # è¿™é‡Œè¿”å›ç¤ºä¾‹æ•°æ®
        return []

    def _identify_trend_reason(self, videos: List[Dict[str, Any]]) -> str:
        """è¯†åˆ«è¶‹åŠ¿åŸå› """
        # ç¤ºä¾‹ï¼šåˆ†æè§†é¢‘ç‰¹å¾è¯†åˆ«åŸå› 
        reasons = []

        # æ£€æŸ¥æ˜¯å¦æœ‰çƒ­é—¨è¯é¢˜æ ‡ç­¾
        hot_tags = ['çƒ­é—¨', 'çˆ†ç«', 'ç—…æ¯’', 'Trending']
        for video in videos:
            tags = video.get('tags', [])
            if any(tag in hot_tags for tag in tags):
                reasons.append('è¯é¢˜æ ‡ç­¾')

        return '; '.join(reasons) if reasons else 'è‡ªç„¶å¢é•¿'

    def _extract_common_words(self, titles: List[str]) -> Dict[str, int]:
        """æå–æ ‡é¢˜å¸¸ç”¨è¯"""
        from collections import Counter
        import re

        all_words = []
        for title in titles:
            # ç®€å•åˆ†è¯ï¼ˆå®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨jiebaç­‰åˆ†è¯å·¥å…·ï¼‰
            words = re.findall(r'\w+', title.lower())
            all_words.extend(words)

        # è¿‡æ»¤åœç”¨è¯
        stop_words = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'å®ƒ', 'ä»¬', 'è¿™ä¸ª', 'é‚£ä¸ª', 'ä¸€ä¸ª'}
        filtered_words = [w for w in all_words if w not in stop_words and len(w) > 1]

        return dict(Counter(filtered_words).most_common(10))

    def _count_frequency(self, items: List[str]) -> Dict[str, int]:
        """ç»Ÿè®¡é¢‘æ¬¡"""
        from collections import Counter
        return dict(Counter(items).most_common(20))


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºåŠ¨æ€è¿½è¸ªåŠŸèƒ½"""
    config = get_config()
    tracker = DynamicTracker(config)

    # ç”Ÿæˆæ¯æ—¥æ‘˜è¦
    digest = tracker.generate_daily_digest()

    # ä¿å­˜æ‘˜è¦
    output_dir = Path('output/dynamic_tracking')
    ensure_dir(output_dir)

    digest_file = output_dir / f"daily_digest_{datetime.now().strftime('%Y%m%d')}.md"
    with open(digest_file, 'w', encoding='utf-8') as f:
        f.write(digest)

    logger.info(f"æ¯æ—¥æ‘˜è¦å·²ä¿å­˜: {digest_file}")
    print(digest)


if __name__ == '__main__':
    main()
