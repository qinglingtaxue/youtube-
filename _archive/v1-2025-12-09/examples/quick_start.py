#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿå¼€å§‹ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨YouTubeè§†é¢‘ç ”ç©¶å·¥ä½œæµçš„åŸºæœ¬åŠŸèƒ½
"""

import sys
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))

from utils.logger import setup_logger, get_default_log_file
from utils.config import get_config
from utils.file_utils import ensure_dir, write_text
from research.data_collector import DataCollector
from analysis.pattern_analyzer import PatternAnalyzer
from workflow.workflow_manager import WorkflowManager

def quick_start_example():
    """
    å¿«é€Ÿå¼€å§‹ç¤ºä¾‹
    æ¼”ç¤ºä¸‰äº‹ä»¶å·¥ä½œæµçš„å®Œæ•´æµç¨‹
    """
    logger = setup_logger('quick_start')
    logger.info("=" * 60)
    logger.info("YouTubeè§†é¢‘ç ”ç©¶å·¥ä½œæµ - å¿«é€Ÿå¼€å§‹ç¤ºä¾‹")
    logger.info("=" * 60)

    # æ­¥éª¤1ï¼šé…ç½®åˆå§‹åŒ–
    logger.info("\nğŸ“‹ æ­¥éª¤1ï¼šé…ç½®åˆå§‹åŒ–")
    config = get_config()
    logger.info(f"é…ç½®æ–‡ä»¶åŠ è½½å®Œæˆ: {config.config_path or 'é»˜è®¤é…ç½®'}")

    # è®¾ç½®æ—¥å¿—æ–‡ä»¶
    log_file = get_default_log_file()
    ensure_dir(Path(log_file).parent)
    logger.info(f"æ—¥å¿—æ–‡ä»¶: {log_file}")

    # æ­¥éª¤2ï¼šäº‹ä»¶1 - æ•°æ®æ”¶é›†
    logger.info("\nğŸ” æ­¥éª¤2ï¼šäº‹ä»¶1 - æ•°æ®æ”¶é›†")
    logger.info("æ­£åœ¨æ”¶é›†YouTubeè§†é¢‘æ•°æ®...")

    try:
        # åˆå§‹åŒ–æ•°æ®æ”¶é›†å™¨
        collector = DataCollector(config)

        # æœç´¢å…³é”®è¯
        keywords = ['æ•™ç¨‹', 'æ•™å­¦', 'å­¦ä¹ ']
        video_data = []

        for keyword in keywords:
            logger.info(f"æœç´¢å…³é”®è¯: {keyword}")
            videos = collector.search_videos(
                query=keyword,
                max_results=10,  # é™åˆ¶æ•°é‡ä»¥ä¾¿å¿«é€Ÿæ¼”ç¤º
                order='viewCount'
            )
            video_data.extend(videos)
            logger.info(f"æ‰¾åˆ° {len(videos)} ä¸ªè§†é¢‘")

        logger.info(f"æ€»å…±æ”¶é›†åˆ° {len(video_data)} ä¸ªè§†é¢‘")

        # ä¿å­˜åŸå§‹æ•°æ®
        output_dir = Path('output/quick_start')
        ensure_dir(output_dir)

        raw_data_file = output_dir / 'raw_videos.json'
        import json
        with open(raw_data_file, 'w', encoding='utf-8') as f:
            json.dump(video_data, f, ensure_ascii=False, indent=2)
        logger.info(f"åŸå§‹æ•°æ®å·²ä¿å­˜åˆ°: {raw_data_file}")

    except Exception as e:
        logger.error(f"æ•°æ®æ”¶é›†å¤±è´¥: {e}")
        logger.info("è¯·æ£€æŸ¥MCPæœåŠ¡å™¨é…ç½®å’Œç½‘ç»œè¿æ¥")
        return

    # æ­¥éª¤3ï¼šäº‹ä»¶2 - æ¨¡å¼åˆ†æ
    logger.info("\nğŸ”¬ æ­¥éª¤3ï¼šäº‹ä»¶2 - æ¨¡å¼åˆ†æ")
    logger.info("æ­£åœ¨åˆ†æè§†é¢‘æ•°æ®ä¸­çš„æ¨¡å¼...")

    try:
        # åˆå§‹åŒ–æ¨¡å¼åˆ†æå™¨
        analyzer = PatternAnalyzer(config)

        # åˆ†æè§†é¢‘æ¨¡å¼
        result = analyzer.analyze_videos(video_data)
        cases = result['selected_cases']

        logger.info(f"å‘ç° {len(cases)} ä¸ªå…¸å‹æ¡ˆä¾‹")

        # ä¿å­˜åˆ†æç»“æœ
        patterns_file = output_dir / 'patterns.json'
        with open(patterns_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        logger.info(f"æ¨¡å¼åˆ†æç»“æœå·²ä¿å­˜åˆ°: {patterns_file}")

        # æ˜¾ç¤ºå‰5ä¸ªæ¡ˆä¾‹
        logger.info("\nğŸ“Š å‰5ä¸ªå…¸å‹æ¡ˆä¾‹:")
        for i, case in enumerate(cases[:5], 1):
            pattern_name = case.get('pattern_name', 'æœªçŸ¥æ¨¡å¼')
            title = case.get('title', '')[:30]
            views = case.get('view_count', 0)
            logger.info(f"{i}. {pattern_name} - {title}... ({views:,}æ¬¡è§‚çœ‹)")

    except Exception as e:
        logger.error(f"æ¨¡å¼åˆ†æå¤±è´¥: {e}")
        return

    # æ­¥éª¤4ï¼šäº‹ä»¶3 - æ¨¡æ¿ç”Ÿæˆ
    logger.info("\nğŸ“ æ­¥éª¤4ï¼šäº‹ä»¶3 - æ¨¡æ¿ç”Ÿæˆ")
    logger.info("åŸºäºåˆ†æç»“æœç”Ÿæˆå†…å®¹æ¨¡æ¿...")

    try:
        # åˆå§‹åŒ–å·¥ä½œæµç®¡ç†å™¨
        workflow = WorkflowManager(config)

        # ç”Ÿæˆç ”ç©¶æŠ¥å‘Š
        report = workflow.generate_report(
            video_data=video_data,
            patterns=cases,
            template_type='report'
        )

        # ä¿å­˜æŠ¥å‘Š
        report_file = output_dir / 'research_report.md'
        write_text(report_file, report)
        logger.info(f"ç ”ç©¶æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")

        # ç”Ÿæˆå†…å®¹åˆ›ä½œæŒ‡å—
        guide = workflow.generate_content_guide(
            patterns=cases,
            target_audience='åˆå­¦è€…'
        )

        guide_file = output_dir / 'content_guide.md'
        write_text(guide_file, guide)
        logger.info(f"å†…å®¹åˆ›ä½œæŒ‡å—å·²ç”Ÿæˆ: {guide_file}")

    except Exception as e:
        logger.error(f"æ¨¡æ¿ç”Ÿæˆå¤±è´¥: {e}")
        return

    # æ€»ç»“
    logger.info("\n" + "=" * 60)
    logger.info("âœ… å¿«é€Ÿå¼€å§‹ç¤ºä¾‹æ‰§è¡Œå®Œæˆï¼")
    logger.info("=" * 60)
    logger.info("\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
    logger.info(f"  - åŸå§‹è§†é¢‘æ•°æ®: {raw_data_file}")
    logger.info(f"  - æ¨¡å¼åˆ†æç»“æœ: {patterns_file}")
    logger.info(f"  - ç ”ç©¶æŠ¥å‘Š: {report_file}")
    logger.info(f"  - å†…å®¹åˆ›ä½œæŒ‡å—: {guide_file}")
    logger.info(f"  - è¿è¡Œæ—¥å¿—: {log_file}")
    logger.info("\nğŸ’¡ æç¤º:")
    logger.info("  - æŸ¥çœ‹outputç›®å½•ä¸‹çš„æ–‡ä»¶äº†è§£è¯¦ç»†ç»“æœ")
    logger.info("  - å¯ä»¥ä¿®æ”¹config/config.yamlè‡ªå®šä¹‰é…ç½®")
    logger.info("  - ä½¿ç”¨æ›´å¤šå…³é”®è¯å¯ä»¥è·å¾—æ›´å¥½çš„åˆ†æç»“æœ")

if __name__ == '__main__':
    print("\n" + "=" * 60)
    print("YouTubeè§†é¢‘ç ”ç©¶å·¥ä½œæµ - å¿«é€Ÿå¼€å§‹ç¤ºä¾‹")
    print("=" * 60)
    print("\næœ¬ç¤ºä¾‹å°†æ¼”ç¤ºå®Œæ•´çš„ä¸‰äº‹ä»¶å·¥ä½œæµç¨‹ï¼š")
    print("1. äº‹ä»¶1ï¼šæ”¶é›†YouTubeè§†é¢‘æ•°æ®")
    print("2. äº‹ä»¶2ï¼šåˆ†æè§†é¢‘æ¨¡å¼")
    print("3. äº‹ä»¶3ï¼šç”Ÿæˆå†…å®¹æ¨¡æ¿å’ŒæŠ¥å‘Š")
    print("\nå¼€å§‹æ‰§è¡Œ...\n")

    try:
        quick_start_example()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
    except Exception as e:
        print(f"\n\nâŒ æ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
